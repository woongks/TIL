### 안정성 및 이중화

상용 시스템을 장애로부터 보호하기 위해서 빠트릴 수 없는 구조가 바로 안정성과 이중화다.

상용 시스템에서는 인프라가 '업무 기능의 토대'가 되지만 요구되는 몇 가지가 있다. 그 중 하나가 안정성이다. 고가용성이라고도 한다.

안정성, 고가용성이란, 시스템 서비스가 가능한 한 멈추지 않도록 하는 것을 말한다.

안정성, 고가용성의 목표

1. 고장, 장애에 의한 정지가 발생하지 않을 것
2. 고장, 장애가 발생해도 복구할 수 있을 것
3. 고장, 장애가 발생한 것을 검출할 수 있을 것
4. 고장, 장애가 발생해도 데이터가 보호될 것

컴포넌트 이중화: 1, 2
컴포넌트 감시: 3
데이터 백업: 4

상용 웹 시스템에서는 미들웨어 기능이나 구조로 이중화, 감시, 백업의 세 가지 수단을 구현해서 목표를 실현하고 있다. 또한, 이중화에는 안정성 확보 이외에도 다른 용도가 있다.

#### 이중화란?

이중화는 하나의 기능을 병렬로 여러 개 나열해서 하나에 장애가 발생해도 다른 것을 이용해서 서비스를 계속할 수 있는 것을 가리킨다. 하나의 기능이 병렬로 가동되기 때문에 이런 고가용성에 대한 의미뿐만 아니라 확장성이나 부하 분산 같은 성능에 대한 의미도 가진다.

이중화에 의한 안정성은 다양한 계층에서 실현할 수 있다.

1. H/W 컴포넌트 계층

- 전원이나 네트워크, 하드디스크 이중화다. 신뢰도가 비교적 낮은 부분과 데이터 보호를 목적으로 한다.

2. 시스템 계층

- 여러 서버에서 동일한 처리를 하는 서버 이중화다. 특정 서버의 처리가 중단돼도 다른 서버에서 처리를 지속해서 사용자에게는 영향을 주지 않는 것이 목적이다.

3. 물리적 위치 계층

- 시스템을 서로 다른 위치에서 운영하는 이중화다. 비용이 들지만 중요한 시스템을 위해 많은 기업들이 채택하는 방식이다. 비용과 신뢰도는 상호 상호의존관계다. 얼마나 비용을 아껴서 시스템의 신뢰도를 높이는가가 관건이다.

### 서버 내 이중화

일반적인 서버 내부 컴포넌트에서는 전원, 팬 등이 이중화돼 있다. 이들 중 하나가 망가져도 서버가 정상 가동하도록 설계돼 있다.

랙 뒤쪽의 양 끝에는 전원 탭이 붙어 있다. 양 끝에 있는 이유는 이중화 때문이다.
서버 설치 시에 이와 같이 설치해 두면 장애를 예방할 수 있다. 또한, 대규모 데이터 센터에서는 각 전원 탭이 별도 분전반이나 UPS에 접속돼 있어서 전원 장애에 대비하고 있다.

안정성을 고려할 때 중요한 것은 양쪽 전원 탭의 전력 합계를 최대로 사용하는 것이 아니라, 한쪽 전원 탭 전력만으로 서버가 가동될 수 있도록 소비 전력 합계를 낮추는 것이다. 한쪽 전원이 모두 공급되지 않아도 다른 한쪽의 전원만으로 시스템을 가동할 수 있기 때문이다. 서버의 소비 전력은 서버 사양서에 기록돼 있다.

#### 네트워크 인터페이스 이중화

PCI 슬롯에 꽂은 카드도 이중화가 가능하다. 네트워크 인터페이스나 파이버 채널 포트에는 이중화 기능이나 이중화를 실현하는 소프트웨어가 있다. 이 기능들을 전제로 카드 이중화 및 포트 이중화를 할 수 있다. 여러 개의 카드에 복수의 포트가 탑재되는 것이다. 이런 구성을 통해 카드 장애 및 포트 장애에 대응할 수 있다.
네트워크 인터페이스가 여러 개 있으면 이중화 소프트웨어나 기능을 이용해서 가용성과 성능을 향상시킬 수 있다.

네트워크 인터페이스 이중화는 하드웨어 또는 OS로 구현한다. 일반적으로는 액티브-스탠바이 구성이다. 액티브-스탠바이 구성은 마스터-워커 개념에 기반했다. 스탠바이 측은 보통 서비스를 제공하지 않는다. 액티브 측에 어떤 문제가 발생하면 스탠바이 장비로 교체돼서 스탠바이가 액티브로 변경된다. 이렇게 교체하는 것을 페일오버라고 한다.

네트워크 인터페이스 이중화의 대표적인 구현 방법 중 하나는 리눅스 OS의 본딩이다. 본딩에는 몇 가지 모드가 있는데, 그중 하나인 액티브-스탠바이 구성은 '액티브-백업'이라고 한다. 어떤 인터페이스가 마스터가 되는지는 설정에서 지정할 수 있다.

본딩이 이중화된 인터페이스를 감시하는 방식에는 두 가지가 있다. 'MII 감시'와 'ARP 감시'다. MII 감시는 MII(Media Independent Interface) 규격에 준거한 인터페이스의 링크 감시로, 현재 주류로 자리 잡고 있는 감시 방식이다. MII 감시에는 링크업(인터페이스가 가동되는 것)이 동작하고 있다면 정상이라고 판단한다. 한편, ARP 감시는 특정 IP 주소로 ARP 요청을 보내서 돌아오는 응답 유무에 따라 정상적인지를 확인하는 방법이다.

MII 감시가 선호되는 주된 이유는 다음과 같다:

- 불필요한 폴링 패킷이 전송되지 않는다.
- 폴링 위치로 지정한 IP 주소를 가진 장비에 대해서는 유지관리나 장애를 의식하지 않아도 된다.

물론 ARP 감시로만 인지할 수 있는 장애도 있다.

ARP 감시는 L2 계층에서 실시된다. ARP 요청을 정기적으로 실행해서 응답이 있으면 정상이라 판단한다. ARP 요청은 MAC 주소를 확인하는 브로드캐스트다. (브로드캐스트는 동일 네트워크 내의 모든 주소에 패킷을 전송하는 것)

ARP 감시의 단점은 폴링이 되는 ARP 요청이 동일 네트워크 내의 브로드캐스트이기 때문에 불필요한 트래픽이 증가한다는 것이다. 따라서 이 불필요한 트래픽을 고려해서 감시 빈도를 너무 높게 설정하지 않는 것이 중요하다. ARP 감시는 일반적으로 1~2초 간격 정도로 설정한다. 페일오버 구조는 감시 방법에 상관없이 동일하다.

인터페이스가 페일오버하면 스위치의 MAC 주소 테이블이 변경되고 통신이 재개된다. 이와 같이 네트워크 인터페이스 이중화인 본딩의 구현은 L3 네트워크보다 낮은 게층에서 구현되고 있다. 때문에 이중화 기능이 L7 애플리케이션 계층에서 구현돼 있으면 이상하다고 판단할 수 있는 감각이 필요하다.

ARP 감시에서는 임의의 IP 주소에 대해 ARP 요청을 보낼 수 있다. 주로 네트워크 게이트웨이로 요청을 보낸다. 반면 MII 감시는 인터페이스 링크 상태를 확인하기 때문에 접속돼 있는 L2스위치만 감시할 수 있다.

ARP 감시가 더 넓은 범위를 감시한다는 것을 알 수 있다. 이와 같이 기능의 장단점과 특성을 고려해서 시스템을 구현해야 한다.

### 저장소 이중화

#### HDD 이중화

저장소 이중화의 주요 대상은 HDD다. HDD는 가동 빈도가 높아서 고장 나기 쉽기 때문이다.

최근에는 잘 사용되지 않지만, 예전에는 서버 저장소를 파이버 채널로 연결하고 SAN(Storage Area Network)이라는 네트워크를 구축하는 방법이 유행했다. 하지만 최근에 접할 수 없는 이유는 높은 비용과 변경(증설 등)에 시간이 걸리기 때문이다.

요즘엔 TCP/IP 프로토콜상에 저장소 네트워크를 구축하는 방식이 늘고 있다. 하지만 TCP/IP 프로토콜상에 SCSI 프로토콜을 이용하는 등, 여러 기술을 조합했기 때문에 사용은 쉽지만 구조가 그만큼 복잡하다. 반면 SAN은 구조가 간단해서 이를 전제로 한 기술이 다시 개발되고 있다.

##### 저장소 내부 구조와 RAID

SAN에서는 IP 주소 대신에 WWN(World Wide Name)이라는 주소를 이용해서 데이터를 전송한다. LAN과는 다른 네트워크 토폴로지다. 또한, HDD 간을 연결하는 내부 버스에는 다양한 규격이 있지만 SAS(Serial Attached SCSI)가 유명하다.

컨트롤러에는 CPU나 캐시가 있으며, HDD의 I/O 제어를 하고 있다. HDD는 전용 박스(엔클로저나 셸프라고 한다)에 저장돼 있어서 증설하기가 쉽다.

각 장비에 IN과 OUT 포트가 있어서 계속 따라가다 보면 HDD까지 원형 연결이 만들어지는 것을 알 수 있다. 저장소는 이 원형 연결을 여러 개 준비해서 HDD 액세스 이중화를 도모하고 있다.

참고로, 서버가 저장소에 액세스할 때는 일반적인 액티브-스탠바이 또는 액티브-액티브 방식을 이용한다.

HDD 자체 이중화는 RAID를 사용한다.
RAID는 여러 HDD를 묶어서 그룹으로 만들고 이것을 논리적인 HDD로 인식하는 기술이다. 논리적 HDD를 LU(Local Unit)라고 한다. 서버가 인식하는 HDD는 이 LU다.

RAID의 장점은 다음과 같다.

1. 안정성 확보
   RAID에서는 HDD에 장애가 발생해도 데이터가 손실되지 않도록 데이터 기록을 이중화한다. HDD는 움직이는 부분이 많아서 고장이 쉽게 난다. 따라서 기록 처리를 이중화한다는 것은 매우 중요한 의미를 가진다.
2. 성능 향상
   RAID에서는 RAID 컨트롤러가 미리 정해놓은 길이로 I/O를 분할해서 복수의 HDD에 대해 병렬로 I/O 처리를 한다. 이 고정 길이를 RAID의 스트라이프 크기라고 부른다.

여러 개의 HDD를 병렬로 동시에 동작시키기 때문에 하나의 HDD를 동작시킬 때보다 I/O 처리 성능이 높아진다. 이 특성을 살리려면 하나의 RAID 그룹에 포함하는 HDD 수를 늘리면 된다. 대신에 한 대의 HDD 고장이 끼치는 영향 범위도 커지기 때문에 상충 관계에 있다고 할 수 있다. 최근에는 I/O 성능 중시 경향이 있어서 하나의 RAID 그룹 크기가 커지고 있다. 8 ~ 15대 정도가 하나의 그룹을 이룬다.

3. 용량 확장
   한 대의 HDD 용량은 기술 발전과 함께 점점 커지고 있지만, 그래도 물리적으로는 600GB, 1TB 등으로 정해져 있다. 논리 HDD는 이런 물리적 한계를 넘어서 자유롭게 용량을 결정할 수 있다. 예를 들어, 10TB를 하나의 파일 시스템으로 취급할 수도 있다.

RAID 구성 패턴

RAID에는 몇 가지 구성 패턴이 존재한다. RAID1, RAID5, RAID10과 같은 구성 패턴이 주류다.

RAID5는 이중화 확보를 위해 패리티라는 오류 수정 부호를 기록한다. 패리티를 하나의 HDD에 집중시키지 않고 분산하는 것이 특징이다. 

RAID1은 일반적으로 OS 디스크 이중화에 사용된다. RAID10은 RAID0과 RAID1을 조합한 구성이다. RAID0은 이중화 없이 HDD에 기록하는 방식이다. 이것은 안정성과 성능을 균형 있게 구성하는 방식이다. RAID10은 복수의 HDD에 병렬로 이중 기록을 하는 방식이다. 이것은 안정성과 성능을 균형 있게 구성하는 방식이다.

RAID5에서는 패리티 연산이 이루어지기 때문에 I/O 성능이 RAID10에 비해 느리다. 하지만 RAID10은 미러링을 하기 때문에 HDD 전체 용량의 1/2 용량밖에 사용할 수 없다. RAID5는 이중화 부분이 적고 '(HDD 수 - 1) / HDD 수'만큼의 용량을 사용할 수 있다. 용량을 중시하는 경우 RAID5를 사용하는 것이 좋다.

HDD가 고장 나면 RAID 구성에 포함된 데이터는 망가지지 않지만, 이중화 구조가 망가진다. 이 이중화 회복을 위해 핫 스페어라고 하는 디스크를 이용한다. 한 대의 HDD가 고장 나면 자동적으로 핫 스페어가 RAID에 포함돼서 이중화 구조를 회복한다. 하지만 핫 스페어가 고갈되고 거기에 HDD까지 파손된 RAID에서는 데이터 손실이 발생하기 때문에 주의가 필요하다.

이와 같이 RAID를 이용해서 이중화를 하더라도 다중 장애 시에는 복구할 수 없는 경우가 있다. 이 때문에 RAID에만 의존하는 것이 아니라 데이터 백업도 반드시 해 두어야 한다.

#### 버스 이중화

저장소 이중화 대상에는 서버와 저장소 사이에 있는 버스도 있다. 예를 들어, RHEL에는 DM-Multipath라는 버스 이중화 기능이 있다.

I/O는 I/O 스케줄러나 드라이버 같은 커널 내부를 통과하지만, DM-Multipath는 I/O 요청을 HBA에 할당해서 페일오버를 실현한다. DM-Multipath는 저장소가 지원하는 경우 액티브-스탠바이로도 사용할 수 있다.

버스 이중화에서 고려해야 할 것은 장애 시의 버스 교체 시간이다. 일반적으로 장애라고 판단하기까지의 HBA 타임아웃 값은 30초 정도로 설정돼 있다. 이것은 불필요한 버스의 페일오버를 발생시키지 않도록 하기 위함이지만, 실제 장애 발생 시에는 페일오버 타임 아웃 시간 동안 저장소 I/O가 정지되기 때문에 처리에 영향을 끼치는 경우에는 값 단축을 검토해야 한다. HBA 드라이버 파라미터로 설정을 변경할 수 있다.

### 웹 서버 이중화

클라이언트의 http 프로토콜 요청을 받는 것은 웹 서버에서 동작하고 있는 웹 서버 프로그램이다. 대표적으로 오픈 소스 웹 서버인 Apache HTTP Server가 있다. 최근 웹 서버는 스레드가 주류이지만, 아파치는 요청 접수시 프로세스 또는 스레드를 선택할 수 있다.

아파치에서는 어느 쪽이든 미리 여러 개를 가동시켜 두어서 클라이언트 요청에 빠르게 대응할 수 있는 구성을 가지고 있다.
여러 개를 가동시켜 두면 프로세스/스레드 중 하나에 장애가 발생해도 다른 프로세스/스레드가 가동되고 있기 때문에 웹 서버의 서비스 전체가 정지되는 일은 없다.

아파치 프로세스/스레드는 httpd다. ps-efL 명령 실행 결과로 프로세스와 스레드의 상태 차이를 알 수 있다.
NLWP는 하나의 프로세스에서 동작하는 스레드 수를 나타낸다.

httpd 프로세스/스레드가 요청을 받지 못하는 상태가 되면 상태 코드로 정보를 알린다. 상태 코드 400번대는 클라이언트 측 에러를 의미하고 500번대는 서버 에러를 의미한다.
웹 서버에 대한 요청은 큐에 쌓이지 않고 바로 에러를 반환한다는 특징이 있다.

#### 서버 이중화

클라리언트가 URL을 입력하면 URL 내의 호스트명을 DNS를 통해 이름 해석을 하고 실제 웹 서버의 IP 주소를 찾는다.

웹 서버를 이중화하는 방법 중 하나는 DNS를 이용해서 하나의 호스트명에 대해 복수의 IP 주소를 반환하는 것이다. 이를 DNS 라운드 로빈이라고 한다. 호스트명에 대해 복수의 IP 주소를 등록해 두는 것으로서 서버 이중화 기법 중 하나다. DNS는 질의에 대해 순서대로 IP 주소를 반환한다. 이 방법은 매우 간단하게 서버를 이중화할 수 이다는 이점이 있지만, 몇 가지 주의 사항이 있다.

1. DNS는 서버 상태를 감시해서 파악하지 않기 때문에 서버가 정지되었어도 그 서버의 주소를 반환한다. 가용성을 중시하는 경우 부적합하다.
2. DNS가 세션 상태를 파악하지 않기 때문에 다음 접속 시에 동일 서버에 접속해야 하는 경우에도 부적합하다. 예를 들어, 웹 서버에 동적 콘텐츠가 있어서 세션 상태를 저장하고 있어야 하는 경우는 DNS 라운드 로빈 방식은 부적합하다.

#### 부하분산 장치를 이용한 웹 서버 이중화

위와 같은 제약 사항 때문에 조금 더 고도화한 이중화 방식이 부하분산 장치(로드 밸런서)다.

세션 유지를 위한 방법은 여러 가지가 있지만, 그 중 하나는 부하분산 장치가 이전에 어느 웹 서버에 요청을 할당했는지를 쿠키에 저장하는 방법이다. 쿠키는 HTTP 프로토콜의 메시지 헤더에 포함되는 요소다. 클라이언트 측에서 쿠키 사용을 허가하면 두 번째 이후 접속부터 HTTP 요청 헤더에 쿠키를 저장해서 접속한다. 부하분산 장치는 이 쿠키를 읽어서 같은 서버에 요청을 할당하는 것이다. 이를 통해 세션 상태를 저장할 수 있다. 부하분산 장치는 임시 대응 관리표로 세션 테이블이라는 것을 만든다. 클라이언트에 요청을 반환할 때는 이 테이블을 참조한다. 세션 상태 저장을 실현하는 기능을 부하분산 장치에서는 '퍼시스턴스' 기능이라고 한다.

퍼시스턴스의 종류:
1. 소스 IP 주소 - 클라이언트 IP 주소를 기반으로 요청을 할당할 웹 서버를 결정한다. (예: 클라이언트 IP 끝자리가 홀수이면 서버 1에 할당)
2. 쿠키 - HTTP 헤더 내에 접속한 웹 서버 정보를 저장한다.
3. URL - URL 구조 내에 접속한 웹 서버 정보를 저장한다.

이런 기술들을 적용하기 전에 각각의 주의 사항 및 고려 사항을 알아 둘 필요가 있다.

출발지 IP 주소를 이용한 퍼시스턴스는 프록시를 경유하면 프록시 서버의 IP 주소가 클라이언트 IP 주소가 돼서 요청이 한쪽으로 몰릴 수 있다. 

쿠키를 사용하는 경우는 각 AP 서버 등이 쿠키를 사용할 때 부하분산 장치가 부여한 쿠키를 덮어쓰기하지 않는지 확인해야 한다.

URL에 정보를 심는 경우, URL은 사용자가 직접 편집 가능한 정보이기 때문에 부정 접속에 대한 대책을 검토해 두어야 한다.
일반적으로는 해시 함수를 이용해서 변경한 값을 심는다.
또한, 부하분산 장치의 첫 접속 시 서버 할당 알고리즘에도 몇 가지 방식이 존재한다.

부하분산 장치의 할당 알고리즘
(아래로 갈수록 복잡하다.)

1. 라운드 로빈 - 서버의 IP 주소에 순서대로 요청을 할당
2. 최소 연결 - 세션 수가 가장 적은 서버의 IP 주소에 요청을 할당한다.
3. 응답 시간 - 서버의 CPU 사용률이나 응답 시간 등을 고려해서 가장 부하가 적은 서버의 IP 주소에 요청을 할당. 

부하분산 장치는 웹 서버의 가동 상태를 감시할 수 있다.
장애를 감지한 경우는 클라이언트 요청을 동적으로 다른 서버에 할당(페일오버)할 수 있다. 좋아 보이는 기능이지만 한 가지 문제가 있다. 

정적 콘텐츠라면 해당되지 않지만, 동적 콘텐츠라면 페일오버와 세션 정보가 사라지기 때문에 세션 상태가 초기화된다. 예를 들어 온라인 쇼핑에서 결제 버튼을 누르기 직전에 오류가 발생하면 과거 입력 내용이 전부 사라지는 것이 있다.

장애 시에 세션 정보를 유지하기 위해서는 페일오버 이외의 다른 구조가 필요하다. 자바에는 세션 정보 보호를 위한 구조가 존재한다.

할당 알고리즘은 간단한 게 좋다. 복잡할수록 높은 부하가 발생한다.

정적 콘텐츠의 경우 세션 수와 CPU 등의 리소스 소비가 비례하기 때문에 단순한 알고리즘인 라운드 로빈이나 최소 연결 방식 등을 주로 사용한다.

부하분산 장치는 고가 장비이기 때문에 소개된 기능 이외에도 'IP:포트' (L4), 혹은 'IP:포트/URL' (L7)을 이용해서 어떤 서버에 리디렉션할지를 정밀하게 설정하는 기능 등도 제공한다.

### AP 서버 이중화

AP 서버 이중화는 두 가지 기능을 이용해서 구현한다. 
1. 웹 서버와 같이 부하분산 장치를 이용하거나 AP 서버가 가진 웹 서버 요청 이중화 기능을 이용해서 AP 서버 요청을 분산시킨다.
2. 세션 정보를 이중화한다. 애플리케이션을 실행하는 AP 서버에서는 세션 정보 이중화 기능을 갖추고 있다. 세션 정보는 애플리케이션의 상태를 가리킨다. 애플리케이션 상태를 일시적으로 기억하는 구조라고 보면 된다.

요청의 분산 및 세션 정보 이중화 기능을 사용해서 AP 서버를 이중화할 수 있다. 상용 AP 서버에는 다양한 종류가 있고 그 중 하나가 오라클 웹로직 서버다. 

1. AP 서버를 선정해서 요청을 AP 서버에 리디렉션한다.
2. 세션 정보를 작성해서 클러스터 내 다른 서버에 복제한다.
3. 세션 정보가 저장된 서버(기본/보조) 정보를 쿠키의 JSESSIONID에 추가해서 반환한다.

웹로직에는 리디렉션용 플러그인이 있어서 웹 서버에 구현된다.
세션 정보는 접속된 AP 서버를 기본으로 하고 보조 세션을 복사해 둔다. 이 서버 정보는 쿠키에 저장돼서 클라이언트에게 반환된다. 클라이언트가 재접속할 때는 웹 서버에 구현된 리디렉션용 플러그인이 기본 서버를 판별해서 해당하는 AP 서버에 요청을 리디렉션한다.

1. 쿠키 정보로부터 AP 서버 1에 리디렉션해서 실패를 감지한다.
2. 보조 세션이 승격해서 기본 세션이 돼서 리디렉션된다.
3. AP 서버 3에는 세션 정보가 없기 때문에 AP 서버 2에서 복사한다.
4. 세션 정보가 저장돼 있는 서버 정보를 쿠키의 JSESSIONID에 추가해서 반환한다.

쿠키 정보를 가지고 보조 세션 정보에 접속해서 세션이 계속 유지되는 것을 알 수 있다. 세션 정보를 복제하면 이를 위한 메모리나 네트워크 리소스 소비량이 늘어나기 때문에 주의가 필요하다.

#### DB 연결 이중화

AP 서버는 3계층형 시스템의 중간에 위치한다. AP 서버가 DB 서버에 접속하는 경우의 이중화가 존재한다. AP 서버에는 DB 서버에 접속 시에 사용할 연결을 사전에 여러 개 생성해 두는 기능이 있다. 이것을 연결 풀링이라고 한다. 웹로직의 데이터 소스를 설정해서 이용한다. 데이터 소스를 이용하는 장점은 애플리케이션이 DB 서버의 IP나 포트 등을 몰라도 된다는 점이다. 애플리케이션은 데이터 소스명만 알면 된다. 그림에서 GET과 CLOSE는 자바 Connection 객체의 getConnection() 및 Close() 메소드에 해당한다. 애플리케이션은 연결 해제를 하지 않아 연결 생성 및 해제 시에 걸리는 시간이나 리소스 없이 고속으로 처리할 수 있다.

폴링에서 웹로직이 감시에 두 번 실패하면 연결이 끊긴 후 재접속 된다. 연결이 모두 사용 중인 경우 설정 최댓값까지 연결 수가 늘며, 최댓값을 초과한 요구가 오면 일정 시간 대기한다. 파라미터는 '연결 예약 타임아웃'이다. 이 경계 값까지 대기한 후 에러를 반환한다. 아파치와 달리 일단 요구가 큐잉된다.

이와 같은 특징으로부터 연결 풀링의 일반적인 설계 방침은 다음과 같이 정리할 수 있다.
1. 최솟값과 최댓값을 동일하게 설정한다.
> 연결을 생성하거나 제거할 때 발생하는 오버헤드를 가능한 한 경감시키기 위해서다.
2. 방화벽 유무를 확인해 둔다.
> 중간에 방화벽이 있다면 오랫동안 사용하지 않은 세션을 자동으로 제거하는 경우가 있기 때문에 방화벽 유무를 확인해두어야 한다. 연결돼 있는 동안 소켓은 Establish 상태이지만, 실제 데이터 교환이 없으면 중간의 네트워크 장비를 해당 연결을 대기 상태라고 간주한다. 특히, 방화벽에서는 보안상의 이유로 장시간 대기 상태인 연결을 절단하는 기능이 있다. 때문에 의도하지 않은 절단이 발생할 수 있어 정기적으로 폴링하는 등 미리 대책을 마련해 두어야 한다.

### DB 서버 이중화

#### 서버 이중화(액티브-스탠바이)

DB 서버 이중화 방법으로는 수년 전부터 주류가 되고 있는 액티브-스탠바이형의 클러스터(Cluster) 구성이 있다. 클러스터 구성은 하드웨어로도 구현할 수 있지만, 일반적으로 클러스터 소프트웨어를 이용한다.

클러스터 구성은 HA(High Availability, 고가용성) 구성이라고 부른다. 클러스터의 노드나 서비스 관계는 마스터-워커 개념을 기반으로 하고 있다. 서버가 정상 동작하는지 확인하기 위한 구조로 '하트비트'(상호 간에 정상 동작하는지 확인하기 위해 정보를 공유한다.)나 '투표 장치' 같은 기능이 존재한다. 서버가 두 대가 있다면 두 대의 서버가 한 가지 역할을 담당한다.

페일오버 구조
1. 장애를 감지한다.
2. 각 노드의 상태가 투표 장치에 기록된다.
3. 장애를 감지하면 서비스를 정지하거나 OS를 재시작한다.
4. 액티브 측이 정지된 것을 인식하고 스탠바이가 서비스를 시작한다.

클러스터 소프트웨어는 등록된 서비스가 정상 동작하고 있는지 정기적으로 확인한다. 이상이 발생하면 서비스를 정지하고 대기하고 있던 스탠바이 측 서비스를 시작해서 서비스를 유지시킨다. 일반적으로 십여 분 정도의 정지 시간으로 서비스를 재개할 수 있다.

클러스터 소프트웨어는 하트비트를 이용해서 상호 간의 상태를 확인하기 때문에 하트비트를 통해 상태를 인식할 수 없게 되면 클러스터 소프트웨어는 페일오버 실시 여부를 판단할 수 없게 된다. 이런 상태를 '스플릿 브레인'이라고 한다.

스플릿 브레인을 해결하는 방법은 다음과 같다.
1. 액티브와 스탠바이가 투표를(상태나 통신 가능한 노드 기록) 한다.
2. 먼저 기록한 쪽이 액티브가 된다.

3노드 이상의 클러스터에서는 상호 인식한 수가 많은 노드가 살아남고 소수파는 정지된다. 이처럼 투표 장치는 하트비트 기능을 보완하는 역할을 한다.

클러스터 구성용 서비스?

클러스터 소프트웨어를 이용한 액티브-스탠바이 구성은 서비스를 병렬로 실행할 수 없고 데이터 일관성을 중시하는 서비스/시스템에 적합하다. 예를 들면 데이터베이스, 파일 서버, 잡 관리 시스템 등이다. 따라서 데이터 갱신이 거의 없어서 데이터 일관성이 중시되지 않고, 서비스 병렬 실행이 가능한 웹 서버나 AP 서버에서는 클러스터 소프트웨어를 사용하지 않는다.

클러스터 S/W 이용 시 주의할 점은 클러스터 S/W도 OS에서 실행되는 S/W이기 때문에 오동작할 가능성이 있다는 것이다. 스플릿 브레인 대책처럼 클러스터 소프트웨어도 자신에게 발생한 장애에 대처할 수 있지만, 100% 신뢰할 수는 없다. 이 때문에 반드시 중요한 데이터는 백업해 두고, 이중 안전 장치가 필요한 경우는 원격 복제 기능 등을 이용한다.

#### 서버 이중화(액티브-액티브)

DB 서버의 데이터 참조, 갱신 부분은 시스템의 병목 지점이 되기 쉬워서 항상 높은 확장성이 요구된다. 
이 때문에 확장 가능한 다양한 기술들이 생겨나고 있다. 

shared everything - 디스크, 데이터를 모든 노드가 공유한다. 장애가 발생해도 다른 노드로 쉽게 처리를 계속할 수 있다.
shared nothing - 각 노드별로 디스크를 가지고 있어서 데이터가 분산된다. 노드를 배치하기 쉽다.

대량의 데이터를 검색하는 경우는 데이터가 분산돼 있기 때문에 쉐어드 낫씽형 쪽이 유리하다. 작은 트랜잭션이 대량으로 발생하는 경우도 노드 추가를 통해 쉽게 확장할 수 있기 때문에 쉐어드 낫씽형이 유리하다. 하지만 확장 시에는 데이터 재배치를 검토 및 설계해야 하기 때문에 확장이 쉽지 않다. 또한, 갱신 시에 데이터 분산 위치를 검토하기 때문에 전반적인 갱신 처리가 느려지는 경향이 있다.

쉐어드 에브리씽형에서는 다른 노드에 있는 메모리 데이터의 일치성을 확인할 필요가 있기 때문에 노드 수를 늘려도 확장이 쉽지 않다. 또한, 모든 노드가 같은 데이터에 액세스할 수 있지만, 이 경우 서로 배타적 제어나 데이터 경합을 하기 때문에 처리 속도가 저하된다.

쉐어드 에브리씽형이 어떤 노드에서건 같은 데이터에 액세스할 수 있기 때문에 가용성 면에서는 유리하지만, 쉐어드 낫씽형에서도 데이터 복제 기능을 이용해서 안정성을 고려한 데이터베이스를 사용할 수 있다.

시스템 특성에 따라 해당 시스템의 병목 현상이나 장애 시 영향 등을 고려하는 것이 중요하다.
클라우드상에서 구현할 때는 쉐어드 낫씽형이 압도적으로 많다. 쉐어드 에브리씽형에서는 공유 디스크가 필수로, 지리적으로 블랙박스화돼 있는 클라우드에선 구성이 어렵기 때문이다. 만약 클라우드상에서 구현한다면 물리 서버를 완전히 점유하는 서비스를 이용해야 한다. 최신 클러스터 소프트웨어에선 클라우드에 대응하기 위해 쉐어드 낫씽으로 변경되고 있다.

트렁크 포트를 사용하려면 VLAN 데이터를 식별할 수 있도록 설정해야 한다. 

### 네트워크 장비 이중화

#### L2 스위치 이중화

두 개의 서버를 스위치 두 개의 포트에 교차해서 꽂으면 스위치 장애에 대비할 수 있다. 스위치를 크로스 케이블 등으로 연결하면 서로 다른 스위치 간 통신이 가능하다. 이것을 캐스케이드라고 한다. 하지만 최근에는 하나의 스위치를 하나의 네트워크에서만 이용하는 것이 아니라 복수의 네트워크에 연결하는 경우도 있다. 이런 경우에는 스위치가 복수의 VLAN을 설정한다.

스위치 간에 VLAN 통신을 할 때는 각각의 VLAN을 연결해야 한다. 하지만 트렁크 포트라는 포트를 이용하면 포트를 복수의 VLAN에 소속시킬 수 있다. 이렇게 트렁크 포트를 사용하는 것이 주류가 되고 있다. 

하지만 트렁크 포트에 장애가 발생하면 스위치 전체에 장애가 발생한다. 네트워크 이중화 방식 중 '링크 집합'이 있다. 서버나 NAS 등에서는 여러 포트를 합쳐서 하나의 이더넷 포트로 이용할 수 있다. 리눅스의 본딩 기능에서도 가능하다. 이것을 '링크 집합(Link Aggregation)'이라고 한다. 링크 집합에서는 보통은 양쪽 포트를 사용하지만, 포트 장애 시에는 해제해서 처리를 계속 할 수 있다. 또한, 양쪽 포트를 사용함으로써 대역이 배로 증가하기 때문에 병목 현상 해결책으로도 이용할 수 있다. 일반적으로 최대 4선 정도까지 묶을 수 있다.

서버 측 포트를 묶은 경우는 꽂고 있는 스위치 쪽 포트도 같은 방식으로 묶어야 한다. 시스코 스위치에서는 이 기능을 '이더 채널'이라고 부른다. 이더 채널에서는 트렁크 포트도 묶을 수 있다. 트렁크 포트는 이 기능을 이용해서 여러 포트를 묶어 사용함으로써 트렁크 포트 통신이 병목 지점이 되는 것을 방지하고 안정성을 높일 수 있다.

여러 개로 묶은 네트워크 포트를 사용해서 부하분산하는 방식에는 여러 가지가 있다.
예를 들어, 본딩에는 라운드 로빈 방식이 있다. 이더 채널에서는 송수신이나 목적지 MAC 주소에 따라 어떤 포트를 사용할지 결정하는 방식이 있다. 목적지 MAC 주소에 따라 부하분산을 하는 경우, 목적지 서버가 한 대라면 하나의 포트에 통신이 집중되기 때문에 설정 시에 이를 고려해야 한다.




### 사이트 이중화



### 감시


### 백업
