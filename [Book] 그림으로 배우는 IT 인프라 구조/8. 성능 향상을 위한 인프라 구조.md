인프라 아키텍처를 그림으로 그려 보면 병목 현상이 발생하기 쉬운 위치를 파악해서 개선 방향을 검토할 수 있다.

### 응답과 처리량

#### 성능 문제의 두 가지 원인

시스템 성능 문제는 대부분 사용자 불만을 통해 인지하게 된다.

- 시스템이 느려서 사용할 수 없다.
- 클릭 후 기다려도 화면이 뜨지 않는다.
- 일괄 처리가 아침이 되도 끝나지 않는다.
- 오후에만 시스템이 갑자기 느려진다.

인프라 관점에서는 다음을 확인해 볼 수 있다.

- 응답 속도가 느린가?
- 처리량이 낮은가?
- 아니면 둘 다인가?

응답은 처리 하나당 소요 시간을 의미하고 처리량은 단위 시간당 처리하는 양을 의미한다.
예를 들어, 검색 엔진에서 키워드를 입력해서 '검색' 버튼을 누른 후 검색 결과가 표시되기까지 걸리는 시간이 응답 시간이다. 처리량은 검색 엔진이 초당 받아 들이는 사용자 수에 해당한다. 응답은 '서비스를 이용하는 한 명의 사용자' 관점 지표이고 처리량은 '서비스 제공자' 관점의 지표라고 할 수 있다.

1분간 10000HTTP 요청을 처리하는 처리량을 갖고 있는 시스템이 있다고 가정한다. 실제 시스템에서는 단일 사용자 응답 시간만으로 무엇을 판단하기에는 부족하다. 때문에 여러 사용자의 평균값을 이용한다. 이때 퍼센타일의 개념을 이용한다. 극단적으로 응답 시간이 긴 사용자는 다른 문제를 내포하고 있을 수 있기 때문에 오차라고 생각하고 평균값에 포함하지 않는다. (AP 서버, DB 서버도 처리량이나 응답 계산에 포함된다.)

##### 응답 문제

사용자 체감 시간에는 각 계층의 처리 시간이 포함되므로 응답 문제가 발생하는 위치는 로그나 실제 장비 시험 등을 통해서 구체적으로 어떤 계층에서 응답 지연이 발생하고 있는지 파악해야 한다. 시스템에 문제가 있다는 사용자 불만을 접수해서 확인해 보면, 사용자가 이용하던 웹 브라우저의 처리 속도가 느려서 문제가 발생하는 경우가 있다.

각 서버의 응답 시간에 대해서는 로그 등을 보면 어느 정도 문제 파악이 가능하다.

응답의 중요한 요소로 시스템에 도달하기까지의 시간과 돌아오기까지의 시간이 있다. 전기 회선을 통과하기 때문에 이 시간이 빛의 속도와 같다고 생각할 수도 있다.
하지만 실제로는 아니다. 웹 브라우저가 액세스하는 경우를 생각해볼 수 있다.
요청이 다양한 스위치나 라우터를 경유해서 최종 시스템에 도달하게 된다. 개별 스위치를 통과하는 데 걸리는 시간은 0이 아니다. 경로가 복잡할수록 지연이 커진다. 정보 교환이 단방향이 아니라서 반드시 어떠한 형태든 응답을 해 가면서 진행을 해야 하기 때문이다.

시스템이 느린 것은 먼저 응답 시간 관점에서 조사해야 한다. 응답 시간 개선에 한계가 보이면 처리량 개선을 통해서 시스템 전체 사용률을 개선하는 것이 일반적이다.

##### 처리량 문제

대량의 데이터를 교환하고 싶은데 영역이 부족한 경우에 처리량 문제가 발생한다. 물리적으로 데이터를 통과시킬 수 없을 때 처리량 관점의 병목 현상이 발생하게 된다.

일반적으로 CPU에서 멀수록 처리량이 낮아진다.

- CPU/메모리 주변은 대역이 넓어서 처리량도 높다.
- NIC: 네트워크 접속 부분에 의해 속도가 크게 떨어질 수 있으므로 밖으로 내보내는 데이터 양을 줄이거나 여러 개를 묶어서 이용할 필요가 있다.
- HDD: 디스크 하나당 처리량이 낮기 때문에 여러 개를 사용해서 처리량을 개선할 필요가 있다.

소프트웨어 관점에서는 예를 들면 CPU가 처리를 감당하지 못하는 처리가 올 때 '대기 행렬'이 발생해서 처리량 한계를 초과할 수도 있다. 처치량은 다수의 요청이 동시에 발생하면 막히기가 쉽다. 예를 들어, '일괄 처리 시간이 느리다'라는 문제는 해당 시간대에 시스템이 다수의 요청을 처리하기 때문에 발생할 가능성이 높다.

응답과 처리량은 밀접한 관계가 있다. 응답이 매우 느린 시스템에서는 다수의 사용자 요청이 시스템 내에 누적되므로 전체 처리량도 낮아진다. 처리량이 포화 상태가 되면 리소스가 부족해져서 응답도 함께 악화된다. 성능 병목 현상을 개선하려면 반드시 양쪽을 고려해서 진행해야 한다.

### 병목 현상이란?

인프라 아키텍처 용어로서 병목 현상이란 처리량을 제한하고 있는 요인을 가리킨다.
AP 서버에서 CPU 사용률이 높아져서 처리량이 한계에 다다르고 있다고 한다면, 처리량이 포화 상태이기 때문에 AP 서버의 응답 시간도 악화된다. 사용자는 응답 시간이 전체적으로 지연되고 있는 것을 느끼게 된다. 이때 AP 서버가 병목 지점이 된다고 할 수 있다.

#### 병목 현상 해결 방법?

병목 현상이 있다는 것을 인지해도 사용자 관점에서 응답이 느려지는 형태로 나타나기 때문에 어디가 원인인지 발견하기 어렵다.

성능 분석의 시작은 먼저 이 병목 현상이 발생하고 있는 위치를 정확히 파악하는 것이다. 이를 위해서는 각 서버의 처리량이나 응답 상황 로그를 취득해서 어느 서버가 병목 지점이 되고 있는지 찾아내는 것부터 시작해야 한다.

병목 지점을 찾았다면 그것을 해결해야 한다. 이때 가능한 주요 접근법에는 두 가지가 있다. 첫 번째는 병목 위치를 파악해서 어떻게든 해결하는 것이다. 이것을 튜닝이라고 한다. 튜닝 시에는 병목 위치를 작은 단위로 '세분화'해서 병목 영역을 더 '집중적으로' 파헤치는 접근법이 유효하다. 서버 내에서는 여러 가지 하드웨어와 소프트어어가 동작하고 있기 때문에 각 컴포넌트의 로그를 확인해 갈 필요가 있다.

다른 한 가지 방법은 시스템 이용자 수를 제한하는 것이다. 이를 유량 제어라고 한다. 대부분의 병목 현상은 예상했던 부하보다 많은 부하가 걸려서 발생하게 된다. 따라서 부하를 제어할 수 있다. 단, 유량 제어는 사용자에게 에러를 반환하는 것이 전부라서 근본적인 해결책은 되지 못한다. 이때는 수평 분할(sharding)을 통해 서버를 증설함으로써 시스템 전체 허용량을 늘리는 접근법을 병용할 필요가 있다.

#### 병목 지점은 반드시 존재한다.

병목 현상은 시스템상에 '반드시' 존재한다. 모든 서버, 소프트웨어, 물리 장비가 균등하게 처리량을 분배하는 것은 이론상 불가능하기 때문이다. 만약 하나의 병목 현상을 해결하기 위해 성능을 개선하면 다른 부분은 성능이 비교적 떨어지게 되기 때문에 또 다른 병목 지점이 된다. 성능 개선 시에는 반드시 '특정 응답을 몇 퍼센트 개선시킨다' 등 시스템 전체 관점에서 목표를 만드는 것이 매우 중요하다.

사용자 측에서 유량 제어를 하지 않고 웹 서버 및 AP 서버를 늘리면 최종적으로는 DB 서버가 병목 지점이 되는 경우가 대부분이다. 이런 이유로 DB 엔지니어는 튜닝에 시달리게 된다. 튜닝 작업을 할 때는 애플리케이션 개발자의 협조가 반드시 필요하다.

### 3계층형 시스템 그림을 통해 본 병목 현상

병목 현상은 5가지로 분류할 수 있다.

1. CPU 병목 현상
2. 메모리 병목 현상
3. 디스크 I/O 병목 현상
4. 네트워크 I/O 병목 현상
5. 애플리케이션 병목 현상

#### CPU 병목 현상 예

반드시 'CPU 사용률이 높다 = 나쁘다'가 성립하지는 않는다. 반대로 'CPU 사용률이 낮다 = 좋다'도 성립하지 않는다. CPU 사용률은 처리 효율성을 나타낼 뿐이다. 병목 현상의 유무와는 관계가 없다.

햄버거 가게에서 점원이 바쁘게 움직이고 있으면 붐비고 있다고 생각할 수도 있다. 하지만 만약 한눈 팔지 않고 열심히 일하는 거면 한 명의 손님이라도 100%의 힘을 쓸 수 있다. CPU도 마찬가지다. 프로세스가 효율적으로 처리를 진행하다 보면 CPU 사용률이 100%가 될 수 있다. (실제 상황에서 CPU 사용률이 100%라면 '여유가 없는 상태'를 의미하기 때문에 주의해야 할 상태다. 시스템 사용자 수가 늘지 않고 데이터 양도 증가하지 않는 '건조한 시스템'이라면 문제가 없지만, 대부분의 시스템은 성장해 가기 때문에 어느 정도 여유가 없으면 확장이 어렵다.)

CPU에 기인한 성능 문제는 주로 다음 두 가지 원인으로 분류할 수 있다.

- CPU를 이용하는 처리가 많아서 대기 행렬이 발생하고 있다.
- CPU 응답이 느리다.

##### 대기 행렬의 병목 현상

점원이 100% 가동률로 일하고 있음에도 고객 행렬이 줄어들지 않는 상태라면 점원이 대기 행렬의 병목 지점이 된다.

CPU 사용률도 마찬가지다. CPU 사용률이 높고 OS상에서 가동하고 있는 프로세스 수가 많으면 대기 행렬에서 병목 현상이 발생한다. 커널 영역에는 OS에 CPU 대기 프로세스를 관리하는 큐가 있다.

큐 대기 프로세스 수가 증가하면 vmstat 등의 유틸리티로 Run-Queue라는 값이 증가하는 것을 확인할 수 있다. 이것은 CPU 사용률만 보고 있으면 알기 어려운 사항으로 주의가 필요하다.

대기 행렬의 병목 현상은 처리량 측면의 문제를 의미한다. 이를 해결하려면 수평적 확장을 하거나 시스템을 개선해서 하나당 처리 시간을 단축하는 것을 해볼 수 있다.

- 개별 처리를 튜닝해서 빠르게 하면 CPU 코어를 점유하는 시간도 짧아지기 때문에 동시 이용 확률이 줄어든다.
- 병렬 처리 정도에 맞추어 CPU를 추가 탑재할 수 있는 서버를 도입하는 것도 대안이 될 수 있다.
- 서버를 한 대 더 추가해서 처리량을 분할하는 안도 있다.

이 방법들 중 하드웨어의 CPU 코어 수를 늘리거나 수평 분할에 따른 서버 수를 늘리거나 하는 튜닝을 '스케일 아웃'이라고 부른다. '스케일'이라는 말은 '규모'라는 의미가 있어, 스케일 아웃은 '규모를 크게 만든다'라는 의미로 사용된다.

기업형 시스템에서는 이용자 수 증감이 적다. 하지만 페이스북이나 트위터 등의 대규모 웹 서비스 시스템에서는 사용자 수가 폭발적으로 증가하고 있으며, 전 세계 사용자가 접속하기 때문에 사용자 증가에 맞추어 서버를 추가해서 스케일아웃하는 아키텍처를 도입하는 것이 필수다.

##### 응답의 병목 현상

대기 행렬을 튜닝하면 처리량 문제는 해결된다. 하지만 처리량 문제를 해결해도 반드시 응답 문제가 해결되는 것은 아니다. 애초에 처리가 느리면 아무리 튜닝을 해도 응답 시간에는 큰 차이가 없다. 응답 시간을 개선하는 방법 몇 가지가 있다.

- 처리 능력을 향상시킨다.
  > 처리 능력을 향상시키는 것을 '스케일업'이라고 한다. 처리 능력이 뛰어난 CPU로 스케일업하면 처리에 필요한 시간이 줄어들기 때문에 응답 시간도 줄어드는 것을 기대할 수 있다. CPU의 '클럭 수'가 그 속도에 해당한다. 하지만 클럭 차이가 요즘엔 그렇게 크지 않아 스케일업으로 성능을 향상시키는 것에는 한계가 있다.
- 병렬로 처리한다.
  > 처리를 분할해서 다수의 CPU 코어에게 동시 처리를 시킬 수 있다. 시스템에서 처리를 '병렬화', '멀티 프로세스화', '멀티 스레드화'해서 복수의 CPU 코어를 이용함으로써 전체적인 처리 응답 시간을 향상시킬 수 있다. 처리를 병렬화할 수 있는가가 중요 사항이 된다. 처리에 따라 병렬화하는 것이 어려운 경우도 있다. 병렬화가 안 되는 경우는 스케일아웃한다고 해도 큰 효과를 보기 어렵다. 병렬화 검토는 인프라만으로 한계가 있기 때문에 애플리케이션 개발자의 협조가 필요하다.

##### CPU 사용률이 오르지 않는 경우

대부분의 애플리케이션에서는 CPU 사용률이 100%에 도달하지 않고 디스크 I/O나 네트워크 I/O에서 막히는 경우가 많다.
동기 I/O의 경우 시스템 콜로 커널에 명령이 가지만, 이것이 완료되지 않으면 프로세스가 다음 처리를 진행하지 않는다. 이 상태의 프로세스는 대기 상태가 되며, CPU를 이용할 수 없기 때문에 CPU 사용률은 올라가지 않는다. 이런 경우는 CPU 사용률이 낮아도 I/O 대기 큐에서 대기하는 프로세스 수가 증가한다.

이 상태는 CPU 병목 현상보다 I/O 병목 현상에 가깝다. 이런 경우, 애플리케이션이 CPU, 메모리, I/O 등의 하드웨어 리소스를 제대로 활용하지 못하는 것이 주된 문제다.

CPU를 이용하는 처리와 디스크 I/O처리를 비교하면 후자가 완료까지 시간이 오래 걸리기 때문에 이런 상황에 이르는 경우가 있다. 특히, 데이터베이스는 I/O가 많아서 발생 빈도가 높다. 개선 방법 몇 가지가 있다.

1. 처리 다중화
   > 처리를 다중화해서 CPU를 적절하게 활용한다. 처리 병렬화와 기본적으로 같은 개념이다. 스레드를 여러 개 가동해서 동기 I/O명령을 스레드 단위로 병행해서 실행하면 CPU 사용률도, I/O 부하도 증가한다. 이를 통해 서버 전체의 리소스 사용 상태를 개선할 수 있다.
2. I/O 비동기화
   > 비동기 I/O를 이용해서 프로세스가 처리 완료를 기다리지 않고 다음으로 넘어가게 한다. CPU처리와 I/O 처리를 동시에 진행할 수 있기 때문에 리소스 사용 상태가 개선된다.

#### 메모리 병목 현상 예

메모리 영역의 병목 현상은 크게 두 가지로 나눌 수 있다.

- 영역 부족
- 동일 영역의 경합

##### 영역 부족에 의한 병목 현상

프로세스가 가동해서 어떤 처리를 하려면 반드시 전용 메모리 영역이 필요하다. 하지만 서버상의 메모리 영역은 유한하다. 64비트 장비에서는 2의 64승 비트 영역까지 이용할 수 있는데, 이것은 16엑사바이트 또는 172억 기가바이트에 해당한다. 매우 큰 영역이지만 역시 유한하다. 유한한 메모리 영역이 부족하지 않도록 OS 커널 측에서 '페이징' 또는 '스와핑'이라는 처리를 해서 빈 메모리를 확보하는 구조가 있다. 즉, 부족한 부분은 디스크 영역으로 보완해서 가상적인 큰 메모리가 있다는 것을 보여 주는 기술이다. 이를 가상 메모리라고 한다. 메모리가 가득 차게 되면 넘친 정보는 디스크에 저장되며, 해당 프로세스가 다시 이 영역을 이용할 때 메모리로 되돌리는 형태다. 이러한 처리가 발생하면 성능 저하가 발생한다. 디스크와 메모리의 성능 차이가 크기 때문이다.
이 문제는 특히 DB 서버에서 문제가 되는 경우가 제법 있다.

##### 동일 데이터에 대한 병목 현상

디스크 I/O 시간을 단축하기 위해 메모리에 캐시로 데이터를 배치해 두는 것도 문제가 될 수 있다. 특정 영역을 복수의 프로세스가 공유하는 경우, 메모리 영역을 참조 또는 갱신할 때 누군가가 그 영역을 관리할 필요가 생긴다. 해당 메모리 영역 (캐시)에 접근 하려면 경합이 발생할 수 밖에 없는데, 이것은 래치(프로세스가 경합해서 빠른쪽이 캐시에 접근)나 대기 행렬로 해결할 수 있다. 이 과정에서 캐시의 용량 이상으로 불필요한 자원이 소모될 수 있다. 이런 문제를 해결하려면 애초에 경합이 발생하지 않도록 복수의 프로세스나 스레드가 같은 메모리 영역을 참조하지 않도록 만들면 된다.

#### 디스크 I/O 병목 현상 예

I/O 병목 현상은 하드 디스크 등의 저장 장치에 대한 I/O 병목이다. I/O는 느려서 병목 지점이 된다면 CPU 수를 늘리거나 클럭 주파수를 높여도 효과가 없다. I/O 효율을 높이거나 I/O 자체를 줄이는 방법을 고민해야 한다.

- 외부 저장소
  > 많은 기업형 환경에서는 데이터베이스의 저장 위치로 외부 저장소를 사용한다. Storage Area Network(SAN)을 경유하는 SAN 저장소나 네트워크를 경유하는 Network Attached Storage(NAS) 저장소 등이 그 예다.

DB 서버가 SAN 저장소에 접속하는 과정은 다음과 같다.
물리적으로 HBA 인터페이스와 SAN 스위치를 통해서 저장 장치와 연결된다.
논리적으로는 시스템 콜을 통해서 I/O 명령을 하고, 이것이 내부적으로 SCSI 프로토콜로 전파된다.

NAS 저장소도 거의 비슷하다. HBA가 NIC가 되고 SAN 스위치가 네트워크 스위치로 바뀌는 점이 물리적 변경 사항이다. 논리적으로는 프로토콜이 NFS 등으로 변경된다.

어떤 경로를 통과하든지 애플리케이션 관점에서는 디스크 I/O의 시스템 콜이 발행되고, OS 커널 측에서 필요한 프로토콜로 요청을 변경해서 디스크나 저장소 측에 요청을 전달한다. 기록 위치가 로컬인지 외부 저장소인지를 의식할 필요가 없다.

RAID를 구성하는 디스크 수가 많을수록 처리량이 높아진다. 처리량은 동일 영역을 이용하고 있는 사용자가 많을수록 저하되기 때문이다. 응답은 아무래도 가까운 로컬 디스크가 가장 빠르다. 이 차이를 따라잡기 위해 외부 저장소는 자신이 가진 메모리 영역(또는 SSD 등)을 잘 활용해서 데이터 캐시를 효율적으로 작성해서 응답 속도를 개선해야 한다.

로컬 디스크를 더 활용하지 못하는 이유는 로컬 디스크에는 OS의 바이너리 파일이나 메모리 페이징, 스왑 영역 등도 저장되기 때문이다. 그렇기 때문에 부하가 높아지면 OS 자체의 동작이 불안정해질 수 있다.

- 순차 I/O와 랜덤 I/O
  > 실제 장비 검증을 위해 PoC나 BMT를 실시하는 사람도 많다. 이때는 I/O 특성을 이해해 둬야 한다. 디스크 I/O에는 순차 액세스와 랜덤 액세스가 있다. 순차는 순서를 따른다는 의미로, 선두부터 차례대로 액세스하는 방식이다. 반면, 랜덤 액세스는 헤드가 움직이면서 해당 위치로 바로 건너뛰는 액세스 방식이다.

순차 액세스는 최고속으로 빠르게 회전하고 있는 형태이고, 랜덤 액세스는 항상 해당 부분을 찾고 있는 형태다. 대상 위치를 찾아서 바늘을 움직여야 하기 때문에 시간이 걸린다.
단일 디스크가 기록 위치인 경우는 순차 방식이 빠르고 랜덤은 느리다. 저장소의 메모리에 액세스하는 거면 고속이기 때문에 랜덤 I/O를 적극적으로 이용한다.
저장 장치 측에서는 이런 메모리처럼 속도가 빠른 영역을 이용하여 디스크의 내용을 캐시하는 구조를 적용할 수 있다. (조각 모음은 분산된 데이터를 한곳에 모으는 처리를 한다. 데이터를 여러 위치에서 찾는 시간을 줄이기 위함이다. 즉, 랜덤 액세스를 줄이기 위한 처리다.)

#### 네트워크 I/O 병목 현상

네트워크를 경유한 I/O는 CPU 버스나 메모리 간 I/O보다도 응답 시간 오버헤드가 크다. 이 때문에 응답을 근본적으로 개선하는 것은 어려우며, 처리량을 개선하는 접근법이나 네트워크 I/O 자체가 발생하지 않도록 하는 방법이 효과가 있다.

- 통신 프로세스의 병목 현상
  > 네트워크 회선에서는 특히 대역이 중시되는 경향이 있다. '대역이 크다 = 고속 통신'이라고 착각하면 안된다. 통신은 1회 통신으로 전송할 수 있는 데이터 양이 제한돼 있기 때문에 항상 풀 파워로 송수신이 이루어지지 않는다. 따라서 높은 처리량을 실현하는 것이 매우 어렵다.

통신에서 대역을 모두 사용하려면 처리를 다중화해서 병렬화할 필요가 있다. 다중화할수록 통신량이 많아지므로 대역폭이 최대치에 가까운 처리량을 실현할 수 있다. OS나 소프트웨어에 따라 이 다중화를 자동으로 구현하고 있는 것도 있다.

병렬화라는 개념은 대역을 최대로 사용한다는 관점에서 매우 유용한 접근법이다. 특히, CPU의 멀티 코어화가 진행되고 있어서 처리 병렬화의 유용성이 높아지고 있다.

압축을 이용해서 전송량을 줄이는 것도 한 가지 접근 방법이 될 수 있다. 이 접근법은 압축 및 해제 시에 발생하는 CPU 오버헤드를 감안해야 한다.

##### 네트워크 경로의 병목 현상

네트워크에서는 눈에 보이지 않는 부분이 병목 지점이 되기 쉽다.

AP 서버에서 클라이언트PC로, DB 서버에서 AP 서버로 가는 큰 트랜잭션들이 모두 게이트웨이인 특정 라우터를 경유하는 바람에 라우터 처리 한계에 다다를 수 있다.

이런 경우 전용 네트워크를 증설해서 트래픽을 분할할 수 있다.

#### 애플리케이션 병목 현상 예

인프라 측은 스케일업, 스케일아웃 등의 개념을 통해 개선이 가능하다. 하지만 애플리케이션 측도 같은 방식으로 확장되지 않으면 애플리케이션 자체가 병목 지점이 되는 경우가 있다.

알고리즘의 문제라면 인프라 측 리소스를 아무리 늘려도 애플리케이션 처리량이 높아지지 않거나 응답 속도를 개선할 수 없다.

- 데이터 갱신의 병목 현상
  > 데이터베이스를 이용한 시스템에서 자주 발생하는 것이 특정 데이터에 의존하는 처리가 병목 지점이 되는 것이다.

예를 들어, 판매 개수를 기록해야 하는데 '반드시 재고 개수에서 1을 뺀다'라는 처리가 있다면, 일반적으로는 테이블의 특정 레코드 값을 변경하도록 구현된다. 이것은 특정 레코드에 대한 병목 지점이 된다. 서로 같은 데이터를 갱신해야 하기 때문에 이 단계를 넘어가지 않는 이상 다음 처리를 하지 않기 때문이다.

두 가지 개선안이 있다.

1. 값의 캐시화
   별도 서버에 질의를 던지는 것이 병목 지점이 된다면, 더 가까운 장소에 캐시화하는 것이 일반적인 방법이다. 단, 네트워크를 경유하는 질의가 없어지므로 처리 효율이 개선될 수 있지만 병목 지점이라는 것에는 변함이 없어서 근본적인 해결책은 되지 못한다.
2. 병목 지점의 분할
   다른 한 가지는 재고 확인을 엄밀하게 처리하지 않고 레코드를 두 개로 나누는 형태다. 예를 들어, 재고가 200개 있다고 하면 100개씩 레코드를 분할한다. 이 경우 한번에 두 개의 처리를 진행할 수 있어서 처리 다중화가 가능하다. 결과적으로는 재고가 몇 개 있는지 확인하는 데이터 일치성 문제와 한쪽이 먼저 고갈된 경우 데이터 최신성 문제가 새롭게 발생한다.

- 외부 질의의 병목 현상
  > 시스템 하나로 완성되는 시스템은 거의 없다. 대부분의 시스템은 다른 시스템과 데이터 연계 등을 통해 협력할 필요가 있다. 이 부분이 병목 지점이 되는 경우도 있다.
